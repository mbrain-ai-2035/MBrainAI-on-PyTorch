{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62b4244-0060-41c3-a47b-72250f0d9629",
   "metadata": {},
   "source": [
    "## PyTorch入门\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3e8f6e-bcbd-46a6-9f33-8f63e4896be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyterlab-language-pack-zh-CN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f9e3e-96a1-418a-aa9e-e4ab77db720b",
   "metadata": {},
   "source": [
    "大多数机器学习工作流程都涉及处理数据、创建模型、优化模型参数以及保存训练好的模型。本教程向您介绍了在 PyTorch 中实现的完整 ML 工作流程，并提供了有关每个概念的更多信息的链接。\n",
    "\n",
    "我们将使用 FashionMNIST 数据集来训练一个神经网络，该网络可以预测输入图像是否属于以下类别之一：T 恤/上衣、裤子、套头衫、连衣裙、外套、凉鞋、衬衫、运动鞋、包或踝靴。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfe425-d2a7-4417-9d33-cda314f50957",
   "metadata": {},
   "source": [
    "### 处理数据\n",
    "\n",
    "PyTorch 有两个处理数据的原语： torch.utils.data.DataLoader和torch.utils.data.Dataset。 \n",
    "\n",
    "Dataset存储样本及其相应的标签，并DataLoader用可迭代对象包装Dataset。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d247e2c-2649-4157-b101-6da869a6cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d409b8-efce-4807-b4de-5f03809c81f2",
   "metadata": {},
   "source": [
    "PyTorch 提供特定领域的库，例如TorchText、 TorchVision和TorchAudio，所有这些库都包含数据集。在本教程中，我们将使用 TorchVision 数据集。\n",
    "\n",
    "该torchvision.datasets模块包含Dataset许多现实世界视觉数据的对象，如 CIFAR、COCO（完整列表在此处）。\n",
    "\n",
    "在本教程中，我们使用 **FashionMNIST** 数据集。每个 TorchVision 都Dataset包含两个参数：transform和 target_transform分别用于修改样本和标签。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd70d5f-5a23-4fa1-8db1-4e62a0354048",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3bf68b4-06d9-4f92-bab8-ad2dced3ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets. 下载训练数据集\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.  下载测试数据集\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223bc6c-6dec-4df8-af65-38f08b2f58f5",
   "metadata": {},
   "source": [
    "Dataset我们将作为参数传递给DataLoader。这将包装我们数据集上的可迭代对象，并支持自动批处理、采样、混洗和多进程数据加载。\n",
    "这里我们定义批处理大小为 64，即 dataloader 可迭代对象中的每个元素将返回一批 64 个特征和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc11ff65-2681-48c9-9eda-8e18849a5531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders 创建数据训练/测试加载器\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6641279f-c1ac-4171-89f1-41a5a5b2fb14",
   "metadata": {},
   "source": [
    "### 创建模型\n",
    "\n",
    "为了在 PyTorch 中定义神经网络，我们创建一个从nn.Module继承的类。我们在函数中定义网络的层__init__，并在函数中指定数据如何通过网络forward。为了加速神经网络中的操作，我们将其移动到加速器， 例如 CUDA、MPS、MTIA 或 XPU。如果当前加速器可用，我们将使用它。否则，我们使用 CPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8851d83f-c52b-4702-943d-943855c59adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using 'cuda' device\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "# print(f\"Using {device} device\")\n",
    "\n",
    "# device = torch.cuda.current_accelerator().type if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using '{device}' device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90dfb51-39ac-40ea-ad57-1008f256ecc2",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3466b45-43f6-4abf-96e5-ccfd5d2fbba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e8fe4e-3fab-44bc-91c1-075cc3458d90",
   "metadata": {},
   "source": [
    "### 优化模型参数\n",
    "\n",
    "为了训练模型，我们需要一个损失函数 和一个优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623e2e32-967f-4649-b332-cf3bae7b5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f3dfd-9695-4cd2-b44e-eb06414298d2",
   "metadata": {},
   "source": [
    "在单次训练循环中，模型对训练数据集（分批输入）进行预测，并反向传播预测误差以调整模型的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae5c4f90-b7f8-484c-b10c-5ea9c4de7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error 计算预测error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation BP算法\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c8b6d-8429-43b1-840a-f00c6998472f",
   "metadata": {},
   "source": [
    "我们还根据测试数据集检查模型的性能，以确保它正在学习。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0de1b9a-76c9-4f14-abd5-8ff01601d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af004ad-3719-4203-a4b9-f799b05a1c68",
   "metadata": {},
   "source": [
    "训练过程需要经过多次迭代（epoch）。在每个 epoch 中，模型都会学习参数以做出更好的预测。我们打印出模型在每个 epoch 中的准确率和损失；我们希望看到准确率在每个 epoch 中增加，损失减少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d586a642-0951-4ef7-a433-b9c01fa04e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " -----------------------------\n",
      "loss: 2.311127  [   64/60000]\n",
      "loss: 2.299029  [ 6464/60000]\n",
      "loss: 2.283235  [12864/60000]\n",
      "loss: 2.271208  [19264/60000]\n",
      "loss: 2.261518  [25664/60000]\n",
      "loss: 2.232806  [32064/60000]\n",
      "loss: 2.236875  [38464/60000]\n",
      "loss: 2.210459  [44864/60000]\n",
      "loss: 2.206471  [51264/60000]\n",
      "loss: 2.179847  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 2.174459 \n",
      "\n",
      "Epoch 2\n",
      " -----------------------------\n",
      "loss: 2.185943  [   64/60000]\n",
      "loss: 2.175061  [ 6464/60000]\n",
      "loss: 2.125737  [12864/60000]\n",
      "loss: 2.136989  [19264/60000]\n",
      "loss: 2.086734  [25664/60000]\n",
      "loss: 2.032086  [32064/60000]\n",
      "loss: 2.060221  [38464/60000]\n",
      "loss: 1.988787  [44864/60000]\n",
      "loss: 1.992028  [51264/60000]\n",
      "loss: 1.927443  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.925258 \n",
      "\n",
      "Epoch 3\n",
      " -----------------------------\n",
      "loss: 1.951802  [   64/60000]\n",
      "loss: 1.927480  [ 6464/60000]\n",
      "loss: 1.817685  [12864/60000]\n",
      "loss: 1.858215  [19264/60000]\n",
      "loss: 1.736839  [25664/60000]\n",
      "loss: 1.689824  [32064/60000]\n",
      "loss: 1.712008  [38464/60000]\n",
      "loss: 1.615996  [44864/60000]\n",
      "loss: 1.638941  [51264/60000]\n",
      "loss: 1.536315  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 1.554898 \n",
      "\n",
      "Epoch 4\n",
      " -----------------------------\n",
      "loss: 1.611090  [   64/60000]\n",
      "loss: 1.584818  [ 6464/60000]\n",
      "loss: 1.436557  [12864/60000]\n",
      "loss: 1.510724  [19264/60000]\n",
      "loss: 1.380908  [25664/60000]\n",
      "loss: 1.375009  [32064/60000]\n",
      "loss: 1.383614  [38464/60000]\n",
      "loss: 1.311770  [44864/60000]\n",
      "loss: 1.350052  [51264/60000]\n",
      "loss: 1.245751  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.276530 \n",
      "\n",
      "Epoch 5\n",
      " -----------------------------\n",
      "loss: 1.347010  [   64/60000]\n",
      "loss: 1.335170  [ 6464/60000]\n",
      "loss: 1.170853  [12864/60000]\n",
      "loss: 1.277693  [19264/60000]\n",
      "loss: 1.149456  [25664/60000]\n",
      "loss: 1.169182  [32064/60000]\n",
      "loss: 1.181343  [38464/60000]\n",
      "loss: 1.122863  [44864/60000]\n",
      "loss: 1.170372  [51264/60000]\n",
      "loss: 1.076153  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.103600 \n",
      "\n",
      "Epoch 6\n",
      " -----------------------------\n",
      "loss: 1.170555  [   64/60000]\n",
      "loss: 1.176134  [ 6464/60000]\n",
      "loss: 0.995869  [12864/60000]\n",
      "loss: 1.132497  [19264/60000]\n",
      "loss: 1.005689  [25664/60000]\n",
      "loss: 1.031170  [32064/60000]\n",
      "loss: 1.057793  [38464/60000]\n",
      "loss: 1.002982  [44864/60000]\n",
      "loss: 1.053777  [51264/60000]\n",
      "loss: 0.971042  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.992270 \n",
      "\n",
      "Epoch 7\n",
      " -----------------------------\n",
      "loss: 1.047293  [   64/60000]\n",
      "loss: 1.072730  [ 6464/60000]\n",
      "loss: 0.876242  [12864/60000]\n",
      "loss: 1.036075  [19264/60000]\n",
      "loss: 0.914054  [25664/60000]\n",
      "loss: 0.934141  [32064/60000]\n",
      "loss: 0.977919  [38464/60000]\n",
      "loss: 0.925299  [44864/60000]\n",
      "loss: 0.972686  [51264/60000]\n",
      "loss: 0.901260  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.916413 \n",
      "\n",
      "Epoch 8\n",
      " -----------------------------\n",
      "loss: 0.956538  [   64/60000]\n",
      "loss: 1.000822  [ 6464/60000]\n",
      "loss: 0.790748  [12864/60000]\n",
      "loss: 0.967792  [19264/60000]\n",
      "loss: 0.852097  [25664/60000]\n",
      "loss: 0.863068  [32064/60000]\n",
      "loss: 0.922456  [38464/60000]\n",
      "loss: 0.873243  [44864/60000]\n",
      "loss: 0.913935  [51264/60000]\n",
      "loss: 0.851457  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.861780 \n",
      "\n",
      "Epoch 9\n",
      " -----------------------------\n",
      "loss: 0.887147  [   64/60000]\n",
      "loss: 0.946507  [ 6464/60000]\n",
      "loss: 0.727308  [12864/60000]\n",
      "loss: 0.916935  [19264/60000]\n",
      "loss: 0.807683  [25664/60000]\n",
      "loss: 0.809670  [32064/60000]\n",
      "loss: 0.881020  [38464/60000]\n",
      "loss: 0.837166  [44864/60000]\n",
      "loss: 0.869829  [51264/60000]\n",
      "loss: 0.813909  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.820578 \n",
      "\n",
      "Epoch 10\n",
      " -----------------------------\n",
      "loss: 0.831822  [   64/60000]\n",
      "loss: 0.903100  [ 6464/60000]\n",
      "loss: 0.678343  [12864/60000]\n",
      "loss: 0.877430  [19264/60000]\n",
      "loss: 0.774094  [25664/60000]\n",
      "loss: 0.768838  [32064/60000]\n",
      "loss: 0.847941  [38464/60000]\n",
      "loss: 0.810935  [44864/60000]\n",
      "loss: 0.835650  [51264/60000]\n",
      "loss: 0.784088  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.788042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n -----------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a071f-aa97-466a-b827-a32996cfe549",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c80613-49dd-4dd9-9d30-d92b2af56f99",
   "metadata": {},
   "source": [
    "保存模型的常用方法是序列化内部状态字典（包含模型参数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae73b4a0-53fb-4fd9-8311-de9a4d5b5afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/FashionMNIST_model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e192c-0d55-479c-b7b3-8ebeaf31118b",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c34970-6128-4502-9846-657e4d644081",
   "metadata": {},
   "source": [
    "加载模型的过程包括重新创建模型结构和将状态字典加载到其中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e61c4fb-83fc-4091-bea2-020aa43d4124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"models/FashionMNIST_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffee494-2807-4210-ae9a-b92feb2087ad",
   "metadata": {},
   "source": [
    "### 模型预测\n",
    "\n",
    "现在可以使用该模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa67032f-fa21-4c70-987c-4dd9947685a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
